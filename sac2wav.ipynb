{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple notebook to turn SAC to WAV files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set up directories, codes and files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download obspyDMT into a local floder:\n",
    "    \n",
    "        git clone https://github.com/kasra-hosseini/obspyDMT.git /path/to/my/obspyDMT\n",
    "\n",
    "obspyDMT can be installed by:\n",
    "\n",
    "        cd /path/to/my/obspyDMT\n",
    "        pip install -e .\n",
    "\n",
    "Please **do not use** >>pip install obspyDMT<<. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy **process_unit_wav.py** which you can find in this project folder into:\n",
    "    \n",
    "    /path/to/my/obspyDMT/obspyDMT\n",
    "\n",
    "You will find there also some other files named **process_unitXXX.py** in this path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else you will need to run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual suspects:\n",
    "\n",
    "    Anaconda\n",
    "    obspy\n",
    "    numpy, scipy, ...\n",
    "    cartopy \n",
    "\n",
    "The extras:\n",
    "    \n",
    "    SoundFile\n",
    "    natsorted\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "    \n",
    "   **Websites for finding earthquakes, networks and stations:**\n",
    "    - http://www.fdsn.org/networks/\n",
    "    - http://ds.iris.edu/wilber3/find_event\n",
    "    \n",
    "   **Understanding network codes:**\n",
    "    - https://ds.iris.edu/ds/nodes/dmc/tools/data_channels/#???\n",
    "    - https://ds.iris.edu/ds/nodes/dmc/data/formats/seed-channel-naming/\n",
    "    \n",
    "   **How to quickly download earthquakes:**\n",
    "    - https://github.com/kasra-hosseini/obspyDMT\n",
    "    \n",
    "   **Learn more about python, jupyter notebooks and obspy:**\n",
    "    - http://seismo-live.org/\n",
    "    \n",
    "   **How to install Anaconda:**\n",
    "    - https://docs.anaconda.com/anaconda/install/mac-os/\n",
    "    \n",
    "   **What we are using to export the waveforms to WAV files:**\n",
    "    - https://pysoundfile.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTENTION 1: \n",
    "It you have a \"%%capture\" at the top of the cell no output will be shown. If you are suspicious that something is going terribly wrong you can comment out this line and see the whole output again.\n",
    "\n",
    "ATTENTION 2:\n",
    "Basemap is deprecated in favor of the Cartopy project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import \n",
    "\n",
    "You usually do not change this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# solve issue wi\\th autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from IPython import display\n",
    "\n",
    "from soundfile import SoundFile\n",
    "from natsort import natsorted\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy import read, Trace\n",
    "from obspy.signal.tf_misfit import plot_tfr\n",
    "\n",
    "# the file src_sac2wav contains written functions for exporting sac to wav files\n",
    "from src_sac2wav import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DMT_logo.png\" width=\"200\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input for Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============\n",
    "# DOWNLOAD input \n",
    "# ==============\n",
    "\n",
    "save_path = '/mnt/seismodata2/MT/_OUTPUT_/test_obspyDMT_jupyter_final_v03'\n",
    "\n",
    "# Choose between \"event\" and \"continuous\" or \"day\" mode.\n",
    "# When you are choosing \"continuous\" or \"day\" mode, day files will be downloaded regardless of the mode. \n",
    "# In continuous mode the day files are later merged to one long trace and exported as WAV. \n",
    "mode = 'continuous'\n",
    "\n",
    "# Does not download anything but just gives you a table of available events in the timespan you define in start_time/end_time\n",
    "event_info = False\n",
    "\n",
    "start_time = '2021-03-03'\n",
    "end_time = '2021-03-06'\n",
    "\n",
    "# preset and offset make only sense in event mode, will not be used with continuous or day mode!\n",
    "preset = None  # in [SEC] default: 0; put None if you want to use default values\n",
    "offset = 0  # default: 1800 for event-based mode and 0 for continuous mode\n",
    "\n",
    "min_mag = '8.0'\n",
    "max_mag = '10'\n",
    "\n",
    "samplingrate = None  # or None \n",
    "waveform_format = 'sac'  # or mseed \n",
    "\n",
    "event_catalog = 'NEIC_USGS'\n",
    "data_source = 'all'  # all or RESIF\n",
    "\n",
    "network = 'IU'\n",
    "station = 'RAO'\n",
    "channel = 'B*'\n",
    "\n",
    "# ATTENTION!! If this is set to TRUE and the datapath is found, delete it before running obspyDMT\n",
    "reset = False\n",
    "\n",
    "# parallel request is on default with 4 cores \n",
    "parallel_request = True\n",
    "\n",
    "# parallel processing is on default with 4 cores\n",
    "parallel_process = True\n",
    "\n",
    "# instrument response, yes/no\n",
    "instrument_correction = True\n",
    "\n",
    "# process_unit that you want to use:\n",
    "process_unit = 'process_unit_wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output paths will be generated:\n",
    "wav_save, save_fig_path = generate_output_folders(mode, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the obspyDMT command first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### here the input from above is put together for obspyDMT \n",
    "execute_DMT = f'obspyDMT --datapath {save_path} --min_date {start_time} --max_date {end_time}'\\\n",
    "              f' --waveform_format {waveform_format} --data_source {data_source}'\\\n",
    "              f' --pre_process {process_unit}'\n",
    "\n",
    "if mode == 'event':\n",
    "    execute_DMT = execute_DMT + f' --min_mag {min_mag} --max_mag {max_mag}'\\\n",
    "                                f' --event_catalog {event_catalog}'\n",
    "    if preset:\n",
    "        execute_DMT = execute_DMT + f' --preset {preset}'\n",
    "\n",
    "    if offset:\n",
    "        execute_DMT = execute_DMT + f' --offset {offset}'\n",
    "\n",
    "elif mode == 'continuous' or mode == 'day':\n",
    "    execute_DMT = execute_DMT + f' --continuous '\n",
    "\n",
    "else:\n",
    "    sys.exit(f'Mode: {mode} not implemented. Forced exit!')\n",
    "\n",
    "# if samplingrate is not None then add the sampling rate modifier otherwise it \n",
    "# should not change the sampling rate of the waveforms\n",
    "\n",
    "if station == '*':\n",
    "    # This means all channels are considered but some datacentres don't like the wildcard\n",
    "    pass\n",
    "elif station != '*':\n",
    "    execute_DMT = execute_DMT + f' --sta {station}'\n",
    "\n",
    "if channel == '*':\n",
    "    pass\n",
    "elif channel != '*':   \n",
    "    execute_DMT = execute_DMT + f' --cha {channel}'\n",
    "\n",
    "if network == '*':\n",
    "    pass\n",
    "elif network != '*':\n",
    "    execute_DMT = execute_DMT + f' --net {network}'\n",
    "\n",
    "if samplingrate: \n",
    "    execute_DMT = execute_DMT + f' --sampling_rate {samplingrate}'\n",
    "\n",
    "if instrument_correction:\n",
    "    execute_DMT = execute_DMT + f' --instrument_correction'\n",
    "\n",
    "if parallel_request:\n",
    "    execute_DMT = execute_DMT + f' --req_parallel --req_np 10'\n",
    "\n",
    "if parallel_process:\n",
    "    execute_DMT = execute_DMT + f' --parallel_process --process_np 10'\n",
    "\n",
    "if event_info:\n",
    "    execute_DMT = execute_DMT + f' --event_info'\n",
    "    \n",
    "if reset:\n",
    "    execute_DMT = execute_DMT + f'  --reset'\n",
    "        \n",
    "print(f'Executing following command in the next cell:\\n\\n{execute_DMT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention! Only execute the next line if you want to download or update your dataset. If you just want to plot or export some specific data you already downloaded then you do not have to execute the next line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!{execute_DMT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your download was interrupted and raw was not converted to processed, execute this next cell. Otherwise, please skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proc_DMT = f'{execute_DMT} --local'\n",
    "!{proc_DMT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access downloaded data and save as WAV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading station information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No visible output generated with %%caputre.\n",
    "\n",
    "Attnetnion: In some cases there might be a gap in data and the %%capture suppress the Warning messages! If you want to see them then comment the first line of the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# find read_station_information function in src_sac2wav.py if you want to know what is happening inside this function\n",
    "df_all = read_station_information(save_path, '*')\n",
    "# you can change the '*' to a specific event, but this wildcard will give you everything \n",
    "# a data frame (df) is generated with all station event information for your current download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can look at the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot station event distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "ax.set_global()\n",
    "ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "df1 = df_all.drop_duplicates(['stalon','stalat'])\n",
    "ax.scatter(df1['stalon'].astype(float), df1['stalat'].astype(float), c='b', marker='v', s=15, alpha=0.7,  transform=ccrs.PlateCarree())\n",
    "\n",
    "if mode == 'event':\n",
    "    df2 = df_all.drop_duplicates(['evlon','evlat'])\n",
    "    ax.scatter(df2['evlon'].astype(float), df2['evlat'].astype(float), c='r', marker='*', s=65, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "# always save this plot\n",
    "plt.savefig(os.path.join(save_fig_path, 'station_event_map.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Poly-WAV's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate WAV files are automatically written when data is downloaded. When exporting poly-WAV files and Hydrophone channel is not present for landstation a zero trace is created and exportet instead.\n",
    "\n",
    "Even if you can download all possible channels (e.g. Water current, temperature, etc... see also here: https://ds.iris.edu/ds/nodes/dmc/tools/data_channels/#VOC) only seismometer channels are exported to WAV files. Only channels starting with:\n",
    "\n",
    "    XX E       Extremely Short Period  ≥ 80 to < 250< 10 sec\n",
    "    XX S       Short Period  ≥ 10 to < 80< 10 sec\n",
    "    \n",
    "    H       High Broad Band ≥ 80 to < 250≥ 10 sec\n",
    "    B       Broad Band≥ 10 to < 80≥ 10 sec\n",
    "    M       Mid Period> 1 to < 10LLong Period≈ 1\n",
    "    L\t    Long Period\t≈ 1\n",
    "    V       Very Long Period≈ 0.1\n",
    "    \n",
    "    XX U       Ultra Long Period≈ 0.01\n",
    "    XX R       Extremely Long Period≥ 0.0001 to < 0.001\n",
    "\n",
    "will be considered for converting for WAV files. There are even longer/shorter period channels which can be added at a later stage if desired.\n",
    "\n",
    "For instance\n",
    "\n",
    "    VOC measures water current\n",
    "    VKI measures inside Temperature\n",
    "and\n",
    "\n",
    "    the “LOG” channel for the console log\n",
    "    the “SOH” channel for the main state of health channel\n",
    "\n",
    "are skipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!** framerate and bitrate are set to 48000 and PCM_24 when downloaded for the single WAV files. You can change that for the poly files. If you want to change it for the single files you have to change it in **process_unit_wav.py** at the bottom of the file (don't forget to save your changes!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention!** you are setting the mode (event, continous, day) on top of the notebook. Here, you can define another folder to process if you wish. Default is to use the above settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There can be several processed folders depending on your above input\n",
    "\n",
    "'processed': [yes] 'sampling_rate' and [yes] 'instrument_correction'\n",
    "\n",
    "'resamp' : [yes] 'sampling_rate' and [no] 'instrument_correction'\n",
    "\n",
    "'instr': [no] 'sampling_rate' and [yes] 'instrument_correction'\n",
    "\n",
    "'noinstr_noresamp': [no] 'sampling_rate' and [no] 'instrument_correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# SAC to WAV input \n",
    "# ================\n",
    "\n",
    "# this is the path of the above downloaded data, but you can also put a path to other previously downloaded data\n",
    "dmt_folder = save_path\n",
    "\n",
    "# this is the mode from above or adjust to something else you already downloaded\n",
    "wav_mode = mode\n",
    "\n",
    "# which folder you want to confert to poly wavs\n",
    "# put one of these four options:\n",
    "# 'processed', 'resamp', 'instr', 'noinstr_noresamp'\n",
    "folder_to_process = 'instr'\n",
    "\n",
    "# if poly_wav files should be generated. (I left this flag but theoretically if \n",
    "# you do not want poly files you already have the single files from the obspyDMT download.)\n",
    "poly_wav = True\n",
    "\n",
    "# What and how much to process depending on the wav_mode/mode\n",
    "proc_wavs_events = ['20210304_192833.a']  # or ['*_*.*'] \n",
    "proc_wavs_days = [start_time, 3]  # or for days '*'\n",
    "proc_wavs_continuous = [start_time, 3]  # or for days '*' | start_time can also be in this format 'YYYY-MM-DD'\n",
    "\n",
    "station_selection = '*'  # or \"RR05\" or '*' or ['PL08', 'BIG2']\n",
    "channel_selection = '*' # please just give the first letter of the channel you want, eg. B, H, L ...\n",
    "\n",
    "# WAV settings\n",
    "framerate = 48000\n",
    "bitrate = 'PCM_24'\n",
    "\n",
    "# generates automatically plots of SAC files in WAV folder\n",
    "plot_waveforms = True\n",
    "\n",
    "# just in case the paths do not exist yet\n",
    "wav_save, save_fig_path = generate_output_folders(wav_mode, dmt_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n",
      "Mode: continuous\n",
      "****************\n",
      "Days to process:\n",
      "\t['continuous1', 'continuous2', 'continuous3']\n",
      "Working on station: RAO\n",
      "Location: 00\n",
      "Channel Group: ['BH1', 'BH2', 'BHZ', 'BDH']\n",
      "\n",
      "\tChannel BH1.\n",
      "\t\tFolder continuous1\n",
      "\t\t\tAdding IU.RAO.00.BH1.\n",
      "\t\tFolder continuous2\n",
      "\t\t\tAdding IU.RAO.00.BH1.\n",
      "\t\tFolder continuous3\n",
      "\t\t\tAdding IU.RAO.00.BH1.\n",
      "\tLength of trace: 10368000\n",
      "\tNormalizing channelwise after merging continuous waveforms.\n",
      "\n",
      "\tChannel BH2.\n",
      "\t\tFolder continuous1\n",
      "\t\t\tAdding IU.RAO.00.BH2.\n",
      "\t\tFolder continuous2\n",
      "\t\t\tAdding IU.RAO.00.BH2.\n",
      "\t\tFolder continuous3\n",
      "\t\t\tAdding IU.RAO.00.BH2.\n",
      "\tLength of trace: 10368000\n",
      "\tNormalizing channelwise after merging continuous waveforms.\n",
      "\n",
      "\tChannel BHZ.\n",
      "\t\tFolder continuous1\n",
      "\t\t\tAdding IU.RAO.00.BHZ.\n",
      "\t\tFolder continuous2\n",
      "\t\t\tAdding IU.RAO.00.BHZ.\n",
      "\t\tFolder continuous3\n",
      "\t\t\tAdding IU.RAO.00.BHZ.\n",
      "\tLength of trace: 10368000\n",
      "\tNormalizing channelwise after merging continuous waveforms.\n",
      "\n",
      "\tChannel BDH.\n",
      "\t\tFolder continuous1\n",
      "\t\t\t--Missing: continuous1/proc_instr/*RAO*00*BDH\n",
      "\t\tFolder continuous2\n",
      "\t\t\t--Missing: continuous2/proc_instr/*RAO*00*BDH\n",
      "\t\tFolder continuous3\n",
      "\t\t\t--Missing: continuous3/proc_instr/*RAO*00*BDH\n",
      "\t\t\tAdding a zero trace for the hydrophone channel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home_geo/mariat/Codes/sac2wav/src_sac2wav.py:777: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: 10\n",
      "Channel Group: ['BH1', 'BH2', 'BHZ', 'BDH']\n",
      "\n",
      "\tChannel BH1.\n",
      "\t\tFolder continuous1\n",
      "\t\t\tAdding IU.RAO.10.BH1.\n",
      "\t\tFolder continuous2\n",
      "\t\t\tAdding IU.RAO.10.BH1.\n",
      "\t\tFolder continuous3\n",
      "\t\t\tAdding IU.RAO.10.BH1.\n",
      "\tLength of trace: 10368000\n",
      "\tNormalizing channelwise after merging continuous waveforms.\n",
      "\n",
      "\tChannel BH2.\n",
      "\t\tFolder continuous1\n",
      "\t\t\tAdding IU.RAO.10.BH2.\n",
      "\t\tFolder continuous2\n",
      "\t\t\tAdding IU.RAO.10.BH2.\n",
      "\t\tFolder continuous3\n",
      "\t\t\tAdding IU.RAO.10.BH2.\n",
      "\tLength of trace: 10368000\n",
      "\tNormalizing channelwise after merging continuous waveforms.\n",
      "\n",
      "\tChannel BHZ.\n",
      "\t\tFolder continuous1\n",
      "\t\t\tAdding IU.RAO.10.BHZ.\n",
      "\t\tFolder continuous2\n",
      "\t\t\tAdding IU.RAO.10.BHZ.\n",
      "\t\tFolder continuous3\n",
      "\t\t\tAdding IU.RAO.10.BHZ.\n",
      "\tLength of trace: 10368000\n",
      "\tNormalizing channelwise after merging continuous waveforms.\n",
      "\n",
      "\tChannel BDH.\n",
      "\t\tFolder continuous1\n",
      "\t\t\t--Missing: continuous1/proc_instr/*RAO*10*BDH\n",
      "\t\tFolder continuous2\n",
      "\t\t\t--Missing: continuous2/proc_instr/*RAO*10*BDH\n",
      "\t\tFolder continuous3\n",
      "\t\t\t--Missing: continuous3/proc_instr/*RAO*10*BDH\n",
      "\t\t\tAdding a zero trace for the hydrophone channel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home_geo/mariat/Codes/sac2wav/src_sac2wav.py:777: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "stars = '*'*len('Mode: ' + wav_mode)\n",
    "print(f'{stars}')\n",
    "print(f'Mode: {wav_mode}')\n",
    "print(f'{stars}')\n",
    "\n",
    "# creating a new panada dataframe based on above input \n",
    "df_wav = read_station_information(dmt_folder, '*')\n",
    "# you can change the '*' to a specific event, but this wildcard will give you everything \n",
    "\n",
    "if wav_mode == 'continuous':\n",
    "    # does generate continuous wav files;\n",
    "    # ATTNENTION uses all continuous* folders in save_path\n",
    "    export_continuous(df_wav, poly_wav, dmt_folder, folder_to_process, proc_wavs_continuous, station_selection,\n",
    "                      channel_selection, framerate, bitrate, wav_save, plot_waveforms)\n",
    "\n",
    "elif wav_mode == 'event':\n",
    "    # genereates wav files containing specific events\n",
    "    export_event(df_wav, poly_wav, dmt_folder, folder_to_process, proc_wavs_events, station_selection,\n",
    "                 channel_selection, framerate, bitrate, wav_save, plot_waveforms)\n",
    "\n",
    "elif wav_mode == 'day':\n",
    "    # genereates wav files containing specific days\n",
    "    export_day(df_wav, poly_wav, dmt_folder, folder_to_process, proc_wavs_days, station_selection,\n",
    "               channel_selection, framerate, bitrate, wav_save, plot_waveforms)\n",
    "else: \n",
    "    sys.exit(f'Mode: {mode} does not exist or is not implemented. Forced exit!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a particular station that was already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Post-proc and plot\n",
    "# ==================\n",
    "save_figs = True\n",
    "\n",
    "plot_instrument_response = True  # if save_figs = True -> automatically saves in plot folder, otherwise will not be saved\n",
    "\n",
    "filtering = True\n",
    "filter_type = 'bandpass'  # or 'lowpass', 'highpass'\n",
    "freqmin =  1/50 # Hz\n",
    "freqmax = 1     # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: The next dataframe (df_all) gives out all download and not necessary what you converted from SAC to WAV (df_wav). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_sta = df_all['station'].unique()\n",
    "uniq_cha = df_all['channel'].unique()\n",
    "uniq_modes = df_all['mode'].unique()\n",
    "print(f'Available stations:\\n{uniq_sta}')\n",
    "print(f'Available channels:\\n{uniq_cha}')\n",
    "print(f'Available modes/events:\\n{uniq_modes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could also define another folder/event that was previously downloaded, default here is save_path\n",
    "path_to_folder = save_path\n",
    "\n",
    "# specify event\n",
    "event = '20210304_192833.a'  # '20210304_192833.a' or \"continuous01\" \n",
    "\n",
    "# specify folder\n",
    "folder = 'proc_instr'  # 'processed' or \"raw\"\n",
    "\n",
    "# station\n",
    "sta = 'DSB'\n",
    "\n",
    "cha = 'B*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seismograms and Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you plot all available channels of this one stations. Grouped stations and channels are automatically saved when converting from SAC to WAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_to_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3bb42701354c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'*{sta}*{cha}*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mchans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_to_folder' is not defined"
     ]
    }
   ],
   "source": [
    "chans = glob.glob(os.path.join(path_to_folder, event, folder, f'*{sta}*{cha}*'))\n",
    "chans.sort()\n",
    "\n",
    "fig, axs = plt.subplots(len(chans),2, figsize=(10, 3*len(chans)), facecolor='w', edgecolor='k')\n",
    "axs = axs.ravel()\n",
    "fig.subplots_adjust(hspace = 1, wspace=0.5)\n",
    "\n",
    "j = 0\n",
    "for i, trace in enumerate(chans):\n",
    "\n",
    "    tr = read(trace)[0]\n",
    "    if filtering:\n",
    "        tr.filter(filter_type, freqmin=freqmin, freqmax=freqmax)\n",
    "        # tr.filter('highpass',  freqmin=1/50, freqmax=50)\n",
    "    try:\n",
    "        data = tr.data / abs(tr.data).max()\n",
    "        axs[j].plot(tr.times(), data)\n",
    "        axs[j].set_title(tr.stats.channel, weight='bold')\n",
    "        axs[j].set_xlabel('samples')\n",
    "        axs[j].set_ylabel('normalized')\n",
    "\n",
    "        axs[j+1].magnitude_spectrum(data, Fs=tr.stats.sampling_rate, color='C2', alpha=0.5)\n",
    "        axs[j+1].set_title(f'Spectrum: {tr.stats.channel}', weight='bold')\n",
    "        axs[j+1].set_xscale('log')\n",
    "        axs[j+1].set_xlim(0.001, 30)\n",
    "\n",
    "        j += 2\n",
    "    except Exception as exp:\n",
    "        axs[j].set_title(tr.stats.channel, weight='bold')\n",
    "        axs[j].set_xlabel('samples')\n",
    "        axs[j].set_ylabel('normalized')\n",
    "        axs[j+1].set_title(f'Spectrum: {tr.stats.channel}', weight='bold')\n",
    "        axs[j+1].set_xscale('log')\n",
    "        axs[j+1].set_xlim(0.001, 30)\n",
    "        j += 2\n",
    "        continue\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(os.path.join(save_fig_path, f'{sta}_{event}_{folder}_all_channels.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spectrogram my take some time depending on the length of the trace and other settings. Hence for now it is done separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change following settings\n",
    "\n",
    "- fmin    \n",
    "  minimal frequency to be analyzed\n",
    "- fmax    \n",
    "  maximal frequency to be analyzed\n",
    "- nf      \n",
    "  number of frequencies (will be chosen with logarithmic spacing)\n",
    "- w0    \n",
    "  parameter for the wavelet, tradeoff between time and frequency resolution\n",
    "- fft_zero_pad_fac      \n",
    "  integer, if > 0, the signal is zero padded to nfft = next_pow_2(len(st)) * fft_zero_pad_fac to get smoother spectrum in the low frequencies\n",
    "- clim\n",
    "  limits of the colorbars\n",
    "- cmap\n",
    "  colormap for TFEM/TFPM, either a string or matplotlib.cm.Colormap instance\n",
    "  Check here:\n",
    "  https://matplotlib.org/stable/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# dt time step between two samples in st (automatically set)\n",
    "fmin = 0.01\n",
    "fmax = 1.\n",
    "w0=4.\n",
    "nf=64\n",
    "fft_zero_pad_fac=4\n",
    "cmap = 'inferno'\n",
    "\n",
    "chans = glob.glob(os.path.join(path_to_folder, event, folder, f'*{sta}*{cha}*'))\n",
    "chans.sort()\n",
    "for trace in chans:\n",
    "    print(f'Plotting {trace}')\n",
    "    tr = read(trace)[0]\n",
    "    plot_tfr(tr.data, \n",
    "             dt=tr.stats.delta, \n",
    "             fmin=fmin, \n",
    "             fmax=fmax, \n",
    "             w0=w0, \n",
    "             nf=nf, \n",
    "             clim= np.mean(tr.data) + 4 * np.std(tr.data),\n",
    "             cmap=cmap,\n",
    "             fft_zero_pad_fac=fft_zero_pad_fac)\n",
    "    if save_figs:\n",
    "        plt.savefig(os.path.join(save_fig_path, f'{sta}_{tr.stats.channel}_spec_{event}_{folder}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrument response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from obspy import read, read_inventory\n",
    "\n",
    "chans = glob.glob(os.path.join(path_to_folder, event, folder, f'*{sta}*{cha}*'))\n",
    "chans.sort()\n",
    "inresp = glob.glob(os.path.join(path_to_folder, event, 'resp', f'*{sta}*{cha}*'))\n",
    "inresp.sort()\n",
    "\n",
    "pre_filt = [0.001, 0.005, 45, 50]\n",
    "            \n",
    "for i, trace in enumerate(chans):\n",
    "    st = read(trace)\n",
    "    tr = st[0]\n",
    "    inv = read_inventory(inresp[i])\n",
    "    \n",
    "    if save_figs:\n",
    "        out_save = os.path.join(save_fig_path, f'{sta}_{tr.stats.channel}_instrument_response_{event}_{folder}.png')\n",
    "        tr.remove_response(inventory=inv, pre_filt = pre_filt, output=\"DISP\", plot=out_save)\n",
    "    else:\n",
    "        tr.remove_response(inventory=inv, pre_filt= pre_filt,output=\"DISP\", plot=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
